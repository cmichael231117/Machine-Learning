{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment-04\n",
    "## < Linear Regression with Multiple Variables >\n",
    "#### - 20154521 Seokjun Choi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Data\n",
    "    - The training data set.\n",
    "    - The testing fata set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_train = \"data_train.csv\"\n",
    "data_train = np.genfromtxt(path_train, delimiter='\"', usecols = (1,3,5,7))\n",
    "\n",
    "x_train = data_train[:, 0]\n",
    "y_train = data_train[:, 1]\n",
    "z_train = data_train[:, 2]\n",
    "h_train = data_train[:, 3]\n",
    "\n",
    "m_train = len(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_test = \"data_test.csv\"\n",
    "data_test = np.genfromtxt(path_test, delimiter='\"', usecols = (1,3,5,7))\n",
    "\n",
    "x_test = data_test[:, 0]\n",
    "y_test = data_test[:, 1]\n",
    "z_test = data_test[:, 2]\n",
    "h_test = data_test[:, 3]\n",
    "\n",
    "m_test = len(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Objective function\n",
    "    - Use sympy library to formulate the objective function $J(\\theta_0, \\theta_1, \\theta_2, \\theta_3) = \\frac{1}{2m}\\sum_{i=1}^{m}(\\theta_0 + \\theta_1 x_i + \\theta_2 y_i + \\theta_3 z_i - h_i)^2$.\n",
    "    - Take the partial derivatives with respect to $\\theta_0$, $\\theta_1$, $\\theta_2$, and $\\theta_3$.\n",
    "    - The training data set is used to formulate the objective function<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sympy import symbols, diff\n",
    "\n",
    "theta_0 = symbols('theta_0')\n",
    "theta_1 = symbols('theta_1')\n",
    "theta_2 = symbols('theta_2')\n",
    "theta_3 = symbols('theta_3')\n",
    "\n",
    "sum = 0\n",
    "for i in range(m_train):\n",
    "    sum += (theta_0 + theta_1 * x_train[i] + theta_2 * y_train[i]\n",
    "           + theta_3 * z_train[i] - h_train[i])**2\n",
    "j_func = sum /(2 * m_train)\n",
    "\n",
    "partial_0 = diff(j_func, theta_0)\n",
    "partial_1 = diff(j_func, theta_1)\n",
    "partial_2 = diff(j_func, theta_2)\n",
    "partial_3 = diff(j_func, theta_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Formulate another energy function from testing data set to plot the testing error later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum_test = 0\n",
    "for i in range(m_test):\n",
    "    sum_test += (theta_0 + theta_1 * x_test[i] + theta_2 * y_test[i]\n",
    "           + theta_3 * z_test[i] - h_test[i])**2\n",
    "j_func_test = sum /(2 * m_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Set the parameters\n",
    "    - Set $\\theta_0 = -1, \\theta_1 = -1$, $\\theta_2 = -1, \\theta_3 = -1$ before we do linear regression.\n",
    "    - The learning rate $\\alpha$ is 0.00002"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.00002\n",
    "\n",
    "tmp_theta_0 = 1\n",
    "tmp_theta_1 = 1\n",
    "tmp_theta_2 = 1\n",
    "tmp_theta_3 = 1\n",
    "list_theta_0 = list()\n",
    "list_theta_1 = list()\n",
    "list_theta_2 = list()\n",
    "list_theta_3 = list()\n",
    "\n",
    "t = 1\n",
    "iteration = list()\n",
    "\n",
    "tmp_j_value = 0\n",
    "j_value = list()\n",
    "tmp_j_value_test = 0\n",
    "j_value_test = list()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Gradient descent\n",
    "    - Renew the parameters$(\\theta_0, \\theta_1, \\theta_2, \\theta_3)$ until the cost converge.\n",
    "    - $temp 0 := \\theta_0 - \\alpha \\frac{\\partial}{\\partial\\theta_0}J(\\theta_0, \\theta_1, \\theta_2, \\theta_3)$<br>\n",
    "    $temp 1 := \\theta_1 - \\alpha \\frac{\\partial}{\\partial\\theta_1}J(\\theta_0, \\theta_1, \\theta_2, \\theta_3)$<br>\n",
    "    $temp 2 := \\theta_2 - \\alpha \\frac{\\partial}{\\partial\\theta_2}J(\\theta_0, \\theta_1, \\theta_2, \\theta_3)$<br>\n",
    "    $temp 3 := \\theta_3 - \\alpha \\frac{\\partial}{\\partial\\theta_3}J(\\theta_0, \\theta_1, \\theta_2, \\theta_3)$<br>\n",
    "    $\\theta_0 := temp 0$<br>\n",
    "    $\\theta_1 := temp 1$<br>\n",
    "    $\\theta_2 := temp 2$<br>\n",
    "    $\\theta_3 := temp 3$<br>\n",
    "    - Store values in lists to draw graph later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "while True:\n",
    "    if t > 1 and abs(tmp_j_value - j_func.evalf(subs = {theta_0: tmp_theta_0,\n",
    "                                                   theta_1: tmp_theta_1,\n",
    "                                                   theta_2: tmp_theta_2,\n",
    "                                                   theta_3: tmp_theta_3})) <= 0.001:\n",
    "        #print(finish)\n",
    "        break\n",
    "    tmp_j_value = j_func.evalf(subs = {theta_0: tmp_theta_0,\n",
    "                                       theta_1: tmp_theta_1,\n",
    "                                       theta_2: tmp_theta_2,\n",
    "                                       theta_3: tmp_theta_3})\n",
    "    \n",
    "    j_value.append(tmp_j_value)\n",
    "    iteration.append(t)\n",
    "    \n",
    "    \n",
    "    tmp_j_value_test = j_func_test.evalf(subs = {theta_0: tmp_theta_0,\n",
    "                                                 theta_1: tmp_theta_1,\n",
    "                                                 theta_2: tmp_theta_2,\n",
    "                                                 theta_3: tmp_theta_3})\n",
    "    j_value_test.append(tmp_j_value_test)\n",
    "    \n",
    "    #print(t, tmp_j_value, '\\n')\n",
    "    t += 1\n",
    "    \n",
    "    list_theta_0.append(tmp_theta_0)\n",
    "    list_theta_1.append(tmp_theta_1)\n",
    "    list_theta_2.append(tmp_theta_2)\n",
    "    list_theta_3.append(tmp_theta_3)\n",
    "    temp0 = tmp_theta_0 - learning_rate * partial_0.evalf(subs = {theta_0: tmp_theta_0,\n",
    "                                                                  theta_1: tmp_theta_1,\n",
    "                                                                  theta_2: tmp_theta_2,\n",
    "                                                                  theta_3: tmp_theta_3})\n",
    "    temp1 = tmp_theta_1 - learning_rate * partial_1.evalf(subs = {theta_0: tmp_theta_0,\n",
    "                                                                  theta_1: tmp_theta_1,\n",
    "                                                                  theta_2: tmp_theta_2,\n",
    "                                                                  theta_3: tmp_theta_3})\n",
    "    temp2 = tmp_theta_2 - learning_rate * partial_2.evalf(subs = {theta_0: tmp_theta_0,\n",
    "                                                                  theta_1: tmp_theta_1,\n",
    "                                                                  theta_2: tmp_theta_2,\n",
    "                                                                  theta_3: tmp_theta_3})\n",
    "    temp3 = tmp_theta_3 - learning_rate * partial_3.evalf(subs = {theta_0: tmp_theta_0,\n",
    "                                                                  theta_1: tmp_theta_1,\n",
    "                                                                  theta_2: tmp_theta_2,\n",
    "                                                                  theta_3: tmp_theta_3})\n",
    "    tmp_theta_0 = temp0\n",
    "    tmp_theta_1 = temp1\n",
    "    tmp_theta_2 = temp2\n",
    "    tmp_theta_3 = temp3\n",
    "    #print(tmp_theta_0, tmp_theta_1, tmp_theta_2, tmp_theta_3, '\\n')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Plot the estimated parameters using the training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(iteration, list_theta_0, c = 'black')\n",
    "plt.plot(iteration, list_theta_1, c = 'red')\n",
    "plt.plot(iteration, list_theta_2, c = 'green')\n",
    "plt.plot(iteration, list_theta_3, c = 'blue')\n",
    "plt.xlabel('t : iteration')\n",
    "plt.ylabel('value')\n",
    "plt.title('1. The estimated parameters using the training dataset. ')\n",
    "plt.legend(['theta_0', 'theta_1', 'theta_2', 'theta_3'])\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Plot the training error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(iteration, j_value, c = 'blue')\n",
    "plt.xlabel('t : iteration')\n",
    "plt.ylabel('cost value')\n",
    "plt.title('2. The training error using the training dataset')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. Plot the testing error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(iteration, j_value_test, c = 'red')\n",
    "plt.xlabel('t : iteration')\n",
    "plt.ylabel('cost value')\n",
    "plt.title('3. The testing error using the testing dataset')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8. Extra\n",
    "    - We can get the best parameters by using normal equation.\n",
    "    - $\\theta = (X^T X)^{-1} X^T y$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = data_train[:,0:3]\n",
    "X = np.ones((300,1))\n",
    "X = np.concatenate((X,parameters), axis = 1)\n",
    "\n",
    "Y = data_train[:,3]\n",
    "\n",
    "X_transpose = X.T\n",
    "best_params = np.linalg.inv(X_transpose.dot(X)).dot(X_transpose).dot(Y)\n",
    "\n",
    "best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
